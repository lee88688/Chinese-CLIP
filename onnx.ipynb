{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cn_clip.clip import tokenize, image_transform\n",
    "from cn_clip.clip.utils import _MODEL_INFO\n",
    "import onnxruntime\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sess_options = onnxruntime.SessionOptions()\n",
    "text_run_options = onnxruntime.RunOptions()\n",
    "text_run_options.log_severity_level = 2\n",
    "text_onnx_model_path = Path('.') / 'data_path' / 'txt.fp32.onnx'\n",
    "text_session = onnxruntime.InferenceSession(text_onnx_model_path.absolute(), sess_options=text_sess_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = text_session.run(None, { 'text': tokenize('皮球').numpy() })\n",
    "text_vector = r[0]\n",
    "text_vector = text_vector / np.linalg.norm(text_vector[0, :])\n",
    "text_features = torch.tensor(r[0])\n",
    "text_features = text_features / text_features.norm(dim=-1, keepdim=True) # 归一化后的Chinese-CLIP文本特征，用于下游任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('text-result.text', r[0], fmt='%.8f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sess_options = onnxruntime.SessionOptions()\n",
    "img_run_options = onnxruntime.RunOptions()\n",
    "img_run_options.log_severity_level = 2\n",
    "img_onnx_model_path = Path('.') / 'data_path' / 'img.fp32.onnx'\n",
    "img_session = onnxruntime.InferenceSession(img_onnx_model_path.absolute(), sess_options=img_sess_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch = \"ViT-B-16\"\n",
    "preprocess = image_transform(_MODEL_INFO[model_arch]['input_resolution'])\n",
    "# 示例皮卡丘图片，预处理后得到[1, 3, 分辨率, 分辨率]尺寸的Torch Tensor\n",
    "image = preprocess(Image.open(\"examples/pokemon.jpeg\")).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_res = img_session.run(None, { \"image\": image.numpy() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vector = img_res[0]\n",
    "image_vector = image_vector / np.linalg.norm(image_vector[0, :])\n",
    "image_features = torch.tensor(img_res[0])\n",
    "image_features /= image_features.norm(dim=-1, keepdim=True) # 归一化后的Chinese-CLIP图像特征，用于下游任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('image-result.text', img_res[0], fmt='%.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ViT-B-16': {'struct': 'ViT-B-16@RoBERTa-wwm-ext-base-chinese',\n",
       "  'input_resolution': 224},\n",
       " 'ViT-L-14': {'struct': 'ViT-L-14@RoBERTa-wwm-ext-base-chinese',\n",
       "  'input_resolution': 224},\n",
       " 'ViT-L-14-336': {'struct': 'ViT-L-14-336@RoBERTa-wwm-ext-base-chinese',\n",
       "  'input_resolution': 336},\n",
       " 'ViT-H-14': {'struct': 'ViT-H-14@RoBERTa-wwm-ext-large-chinese',\n",
       "  'input_resolution': 224},\n",
       " 'RN50': {'struct': 'RN50@RBT3-chinese', 'input_resolution': 224}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_MODEL_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3681]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features @ text_features.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36813587]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(image_vector, text_vector.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
